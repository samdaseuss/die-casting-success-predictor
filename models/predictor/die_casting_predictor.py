import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.impute import SimpleImputer
import warnings
warnings.filterwarnings('ignore')

class DiecastingQualityPredictor:
    def __init__(self):
        self.model = None
        self.scaler = StandardScaler()
        self.label_encoders = {}
        self.feature_columns = []
        self.target_column = 'passorfail'
        
    def load_and_preprocess_data(self, data_path=None, df=None):
        
        print("ğŸ“Š ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ ì‹œì‘...")
        
        if df is not None:
            self.df = df.copy()
        else:
            # CSV íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë”©
            self.df = pd.read_csv(data_path)
        
        print(f"ì›ë³¸ ë°ì´í„° í¬ê¸°: {self.df.shape}")
        print(f"ê²°ì¸¡ê°’ ê°œìˆ˜:\\n{self.df.isnull().sum()}")
        
        # 1. ê¸°ë³¸ ì •ë³´ ì¶œë ¥
        print("\\nğŸ“‹ ë°ì´í„° ê¸°ë³¸ ì •ë³´:")
        print(self.df.info())
        
        # 2. íƒ€ê²Ÿ ë³€ìˆ˜ í™•ì¸
        print(f"\\nğŸ¯ íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„í¬:")
        print(self.df[self.target_column].value_counts())
        
        # 3. ì „ì²˜ë¦¬ ë‹¨ê³„
        self.df_processed = self._preprocess_features()
        
        return self.df_processed
    
    def _preprocess_features(self):
        """
        í”¼ì²˜ ì „ì²˜ë¦¬ ìˆ˜í–‰
        """
        df = self.df.copy()
        
        # 1. ë‚ ì§œ/ì‹œê°„ í”¼ì²˜ ì²˜ë¦¬
        if 'date' in df.columns:
            df['date'] = pd.to_datetime(df['date'], errors='coerce')
            df['day_of_week'] = df['date'].dt.dayofweek
            df['month'] = df['date'].dt.month
            df['day'] = df['date'].dt.day
        
        if 'time' in df.columns:
            # ì‹œê°„ì„ ë¶„ ë‹¨ìœ„ë¡œ ë³€í™˜
            df['time'] = pd.to_datetime(df['time'], format='%H:%M:%S', errors='coerce')
            df['hour'] = df['time'].dt.hour
            df['minute'] = df['time'].dt.minute
        
        # 2. ì¹´í…Œê³ ë¦¬ ë³€ìˆ˜ ì¸ì½”ë”©
        categorical_columns = ['line', 'name', 'mold_name', 'mold_code', 'heating_furnace']
        
        for col in categorical_columns:
            if col in df.columns:
                # ê²°ì¸¡ê°’ì„ 'Unknown'ìœ¼ë¡œ ì±„ì›€
                df[col] = df[col].fillna('Unknown')
                
                # ë¼ë²¨ ì¸ì½”ë”©
                le = LabelEncoder()
                df[f'{col}_encoded'] = le.fit_transform(df[col].astype(str))
                self.label_encoders[col] = le
        
        # 3. ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ê²°ì¸¡ê°’ ì²˜ë¦¬
        numeric_columns = [
            'molten_temp', 'facility_operation_cycleTime', 'production_cycletime',
            'low_section_speed', 'high_section_speed', 'molten_volume', 'cast_pressure',
            'biscuit_thickness', 'upper_mold_temp1', 'upper_mold_temp2', 'upper_mold_temp3',
            'lower_mold_temp1', 'lower_mold_temp2', 'lower_mold_temp3', 'sleeve_temperature',
            'physical_strength', 'Coolant_temperature', 'EMS_operation_time'
        ]
        
        for col in numeric_columns:
            if col in df.columns:
                # ì¤‘ì•™ê°’ìœ¼ë¡œ ê²°ì¸¡ê°’ ì±„ì›€
                df[col] = df[col].fillna(df[col].median())
        
        # 4. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
        df = self._feature_engineering(df)
        
        # 5. ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±°
        columns_to_drop = ['id', 'date', 'time', 'registration_time'] + categorical_columns
        columns_to_drop = [col for col in columns_to_drop if col in df.columns]
        df = df.drop(columns=columns_to_drop, errors='ignore')
        
        return df
    
    def _feature_engineering(self, df):
        """
        í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ - ìƒˆë¡œìš´ í”¼ì²˜ ìƒì„±
        """
        # ì˜¨ë„ ê´€ë ¨ í”¼ì²˜
        temp_cols = ['upper_mold_temp1', 'upper_mold_temp2', 'upper_mold_temp3',
                     'lower_mold_temp1', 'lower_mold_temp2', 'lower_mold_temp3']
        
        existing_temp_cols = [col for col in temp_cols if col in df.columns]
        if existing_temp_cols:
            df['avg_mold_temp'] = df[existing_temp_cols].mean(axis=1)
            df['temp_variation'] = df[existing_temp_cols].std(axis=1)
        
        # ì†ë„ ê´€ë ¨ í”¼ì²˜
        if 'low_section_speed' in df.columns and 'high_section_speed' in df.columns:
            df['speed_ratio'] = df['high_section_speed'] / (df['low_section_speed'] + 1e-8)
            df['speed_diff'] = df['high_section_speed'] - df['low_section_speed']
        
        # ì˜¨ë„ ì°¨ì´ í”¼ì²˜
        if 'molten_temp' in df.columns and 'avg_mold_temp' in df.columns:
            df['temp_diff_molten_mold'] = df['molten_temp'] - df['avg_mold_temp']
        
        # ì••ë ¥-ë¶€í”¼ ê´€ë ¨ í”¼ì²˜
        if 'cast_pressure' in df.columns and 'molten_volume' in df.columns:
            df['pressure_volume_ratio'] = df['cast_pressure'] / (df['molten_volume'] + 1e-8)
        
        return df
    
    def train_models(self):
        """
        ì—¬ëŸ¬ ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  ìµœì  ëª¨ë¸ ì„ íƒ
        """
        print("\\nğŸ¤– ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
        
        # í”¼ì²˜ì™€ íƒ€ê²Ÿ ë¶„ë¦¬
        X = self.df_processed.drop(columns=[self.target_column])
        y = self.df_processed[self.target_column]
        
        # Pass/Failì„ 1/0ìœ¼ë¡œ ë³€í™˜
        y = (y == 'Pass').astype(int)
        
        self.feature_columns = X.columns.tolist()
        
        # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # í”¼ì²˜ ìŠ¤ì¼€ì¼ë§
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # ì—¬ëŸ¬ ëª¨ë¸ ì •ì˜
        models = {
            'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),
            'GradientBoosting': GradientBoostingClassifier(random_state=42),
            'ExtraTrees': ExtraTreesClassifier(n_estimators=100, random_state=42),
            'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000),
            'SVM': SVC(probability=True, random_state=42)
        }
        
        # ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
        model_scores = {}
        
        for name, model in models.items():
            print(f"\\nğŸ” {name} ëª¨ë¸ í›ˆë ¨ ì¤‘...")
            
            if name in ['LogisticRegression', 'SVM']:
                model.fit(X_train_scaled, y_train)
                y_pred = model.predict(X_test_scaled)
                y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
            else:
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
                y_pred_proba = model.predict_proba(X_test)[:, 1]
            
            accuracy = accuracy_score(y_test, y_pred)
            auc_score = roc_auc_score(y_test, y_pred_proba)
            
            model_scores[name] = {
                'model': model,
                'accuracy': accuracy,
                'auc': auc_score,
                'predictions': y_pred,
                'probabilities': y_pred_proba
            }
            
            print(f"   ì •í™•ë„: {accuracy:.4f}")
            print(f"   AUC: {auc_score:.4f}")
        
        # ìµœì  ëª¨ë¸ ì„ íƒ (AUC ê¸°ì¤€)
        best_model_name = max(model_scores.keys(), key=lambda x: model_scores[x]['auc'])
        self.model = model_scores[best_model_name]['model']
        self.best_model_name = best_model_name
        
        print(f"\\nğŸ† ìµœì  ëª¨ë¸: {best_model_name}")
        print(f"   ì •í™•ë„: {model_scores[best_model_name]['accuracy']:.4f}")
        print(f"   AUC: {model_scores[best_model_name]['auc']:.4f}")
        
        # ìƒì„¸ í‰ê°€ ë¦¬í¬íŠ¸
        self._detailed_evaluation(y_test, model_scores[best_model_name])
        
        # í”¼ì²˜ ì¤‘ìš”ë„ ì¶œë ¥
        self._feature_importance()
        
        return model_scores
    
    def _detailed_evaluation(self, y_test, best_model_info):
        """
        ìƒì„¸ ëª¨ë¸ í‰ê°€
        """
        print("\\nğŸ“Š ìƒì„¸ í‰ê°€ ë¦¬í¬íŠ¸:")
        print("="*50)
        print(classification_report(y_test, best_model_info['predictions'], target_names=['Fail', 'Pass']))
        
        # í˜¼ë™ í–‰ë ¬
        cm = confusion_matrix(y_test, best_model_info['predictions'])
        print("\\ní˜¼ë™ í–‰ë ¬:")
        print(cm)
        
    def _feature_importance(self):
        """
        í”¼ì²˜ ì¤‘ìš”ë„ ì¶œë ¥
        """
        if hasattr(self.model, 'feature_importances_'):
            feature_importance = pd.DataFrame({
                'feature': self.feature_columns,
                'importance': self.model.feature_importances_
            }).sort_values('importance', ascending=False)
            
            print("\\nğŸ” í”¼ì²˜ ì¤‘ìš”ë„ (ìƒìœ„ 10ê°œ):")
            print("="*40)
            for idx, row in feature_importance.head(10).iterrows():
                print(f"{row['feature']:<25}: {row['importance']:.4f}")
    
    def predict_individual_samples(self, df=None):

        print("\\nğŸ¯ ê°œë³„ ìƒ˜í”Œ ì˜ˆì¸¡ ì‹œì‘...")
        
        if df is None:
            df = self.df_processed
        
        X = df[self.feature_columns]
        
        # ìŠ¤ì¼€ì¼ë§ (í•„ìš”í•œ ê²½ìš°)
        if self.best_model_name in ['LogisticRegression', 'SVM']:
            X_scaled = self.scaler.transform(X)
            predictions = self.model.predict(X_scaled)
            probabilities = self.model.predict_proba(X_scaled)[:, 1]
        else:
            predictions = self.model.predict(X)
            probabilities = self.model.predict_proba(X)[:, 1]
        
        # ê²°ê³¼ ì •ë¦¬
        results = []
        for i, (pred, prob) in enumerate(zip(predictions, probabilities)):
            result = {
                'Index': i,
                'Prediction': 'Pass' if pred == 1 else 'Fail',
                'Confidence': prob if pred == 1 else 1-prob,
                'Probability_Pass': prob,
                'Probability_Fail': 1-prob
            }
            results.append(result)
        
        results_df = pd.DataFrame(results)
        
        # ì‹¤ì œê°’ê³¼ ë¹„êµ (ìˆëŠ” ê²½ìš°)
        if self.target_column in df.columns:
            actual = df[self.target_column].values
            results_df['Actual'] = actual
            results_df['Correct'] = (results_df['Prediction'] == actual)
            accuracy = results_df['Correct'].mean()
            print(f"\\nì „ì²´ ì •í™•ë„: {accuracy:.4f}")
        
        return results_df
    
    def predict_individual_samples_one_by_one(self, df=None):
        
        if df is None:
            df = self.df_processed
        
        X = df[self.feature_columns]
        
        if self.best_model_name in ['LogisticRegression', 'SVM']:
            X_scaled = self.scaler.transform(X)
            predictions = self.model.predict(X_scaled)
            probabilities = self.model.predict_proba(X_scaled)[:, 1]
        else:
            predictions = self.model.predict(X)
            probabilities = self.model.predict_proba(X)[:, 1]
        
        results = []
        for i, (pred, prob) in enumerate(zip(predictions, probabilities)):
            result = {
                'Index': i,
                'Prediction': 'Pass' if pred == 1 else 'Fail',
                'Confidence': prob if pred == 1 else 1-prob,
                'Probability_Pass': prob,
                'Probability_Fail': 1-prob
            }
            results.append(result)
        
        results_df = pd.DataFrame(results)
        
        if self.target_column in df.columns:
            actual = df[self.target_column].values
            results_df['Actual'] = actual
            results_df['Correct'] = (results_df['Prediction'] == actual)
            accuracy = results_df['Correct'].mean()
            print(f"\\nì „ì²´ ì •í™•ë„: {accuracy:.4f}")
        
        return results_df
    
    def print_prediction_summary(self, results_df):

        print("\\nğŸ“‹ ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½:")
        print("="*50)
        
        total_samples = len(results_df)
        pass_predictions = (results_df['Prediction'] == 'Pass').sum()
        fail_predictions = (results_df['Prediction'] == 'Fail').sum()
        
        print(f"ì „ì²´ ìƒ˜í”Œ ìˆ˜: {total_samples}")
        print(f"Pass ì˜ˆì¸¡: {pass_predictions} ({pass_predictions/total_samples*100:.1f}%)")
        print(f"Fail ì˜ˆì¸¡: {fail_predictions} ({fail_predictions/total_samples*100:.1f}%)")
        
        # ë†’ì€ í™•ì‹ ë„ ì˜ˆì¸¡
        high_confidence = results_df[results_df['Confidence'] > 0.8]
        print(f"\\në†’ì€ í™•ì‹ ë„(>80%) ì˜ˆì¸¡: {len(high_confidence)}ê°œ")
        
        # ë‚®ì€ í™•ì‹ ë„ ì˜ˆì¸¡ (ì£¼ì˜ í•„ìš”)
        low_confidence = results_df[results_df['Confidence'] < 0.6]
        print(f"ë‚®ì€ í™•ì‹ ë„(<60%) ì˜ˆì¸¡: {len(low_confidence)}ê°œ (ì¬ê²€í†  í•„ìš”)")
        
        if 'Actual' in results_df.columns:
            correct_predictions = results_df['Correct'].sum()
            print(f"\\nì •í™•í•œ ì˜ˆì¸¡: {correct_predictions}/{total_samples} ({correct_predictions/total_samples*100:.1f}%)")
        
        # ìƒ˜í”Œ ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥ (ì²˜ìŒ 20ê°œ)
        print("\\nğŸ” ê°œë³„ ì˜ˆì¸¡ ê²°ê³¼ (ì²˜ìŒ 20ê°œ):")
        print("-"*80)
        for idx, row in results_df.head(20).iterrows():
            status = "âœ…" if row.get('Correct', True) else "âŒ"
            actual_str = f" (ì‹¤ì œ: {row['Actual']})" if 'Actual' in row else ""
            print(f"{status} ìƒ˜í”Œ {row['Index']:3d}: {row['Prediction']:4s} "
                  f"(í™•ì‹ ë„: {row['Confidence']:.3f}){actual_str}")

def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    def create_sample_data():
        np.random.seed(42)
        n_samples = 1000
        
        data = {
            'id': range(1, n_samples + 1),
            'line': np.random.choice(['Line_A', 'Line_B', 'Line_C'], n_samples),
            'name': np.random.choice(['Product_1', 'Product_2', 'Product_3'], n_samples),
            'mold_name': np.random.choice(['Mold_X', 'Mold_Y', 'Mold_Z'], n_samples),
            'time': [f"{np.random.randint(8, 18):02d}:{np.random.randint(0, 60):02d}:{np.random.randint(0, 60):02d}" for _ in range(n_samples)],
            'date': pd.date_range('2024-01-01', periods=n_samples, freq='H'),
            'count': np.random.randint(1, 100, n_samples),
            'working': np.random.choice([0, 1], n_samples),
            'emergency_stop': np.random.choice([0, 1], n_samples, p=[0.9, 0.1]),
            'molten_temp': np.random.normal(700, 20, n_samples),
            'facility_operation_cycleTime': np.random.normal(25, 5, n_samples),
            'production_cycletime': np.random.normal(30, 5, n_samples),
            'low_section_speed': np.random.normal(25, 5, n_samples),
            'high_section_speed': np.random.normal(100, 15, n_samples),
            'molten_volume': np.random.normal(150, 20, n_samples),
            'cast_pressure': np.random.normal(60, 10, n_samples),
            'biscuit_thickness': np.random.normal(12, 2, n_samples),
            'upper_mold_temp1': np.random.normal(200, 15, n_samples),
            'upper_mold_temp2': np.random.normal(200, 15, n_samples),
            'upper_mold_temp3': np.random.normal(200, 15, n_samples),
            'lower_mold_temp1': np.random.normal(200, 15, n_samples),
            'lower_mold_temp2': np.random.normal(200, 15, n_samples),
            'lower_mold_temp3': np.random.normal(200, 15, n_samples),
            'sleeve_temperature': np.random.normal(230, 20, n_samples),
            'physical_strength': np.random.normal(300, 30, n_samples),
            'Coolant_temperature': np.random.normal(25, 3, n_samples),
            'EMS_operation_time': np.random.exponential(2, n_samples),
            'registration_time': pd.date_range('2024-01-01', periods=n_samples, freq='H'),
            'tryshot_signal': np.random.choice([0, 1], n_samples, p=[0.8, 0.2]),
            'mold_code': np.random.choice(['MC001', 'MC002', 'MC003'], n_samples),
            'heating_furnace': np.random.choice(['HF_A', 'HF_B'], n_samples)
        }
        
        pass_prob = (
            (data['molten_temp'] > 680) * 0.3 +
            (data['cast_pressure'] > 55) * 0.3 +
            (data['physical_strength'] > 280) * 0.2 +
            (data['emergency_stop'] == 0) * 0.2 +
            np.random.normal(0, 0.1, n_samples)
        )
        
        data['passorfail'] = ['Pass' if p > 0.5 else 'Fail' for p in pass_prob]
        
        return pd.DataFrame(data)
    
    print("ğŸ­ ë‹¤ì´ìºìŠ¤íŒ… í’ˆì§ˆ ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œ")
    print("=" * 50)
    
    # 1. ë°ì´í„° ë¡œë”© (ì˜ˆì‹œ ë°ì´í„° ì‚¬ìš©)
    # ì‹¤ì œ ì‚¬ìš©ì‹œ: df = pd.read_csv('your_data.csv')
    df = create_sample_data()
    print(f"ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ: {df.shape}")
    
    # 2. ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    predictor = DiecastingQualityPredictor()
    
    # 3. ë°ì´í„° ì „ì²˜ë¦¬
    processed_df = predictor.load_and_preprocess_data(df=df)
    
    # 4. ëª¨ë¸ í›ˆë ¨
    model_scores = predictor.train_models()
    
    # 5. ê°œë³„ ìƒ˜í”Œ ì˜ˆì¸¡
    prediction_results = predictor.predict_individual_samples()
    
    # 6. ê²°ê³¼ ìš”ì•½ ì¶œë ¥
    # predictor.print_prediction_summary(prediction_results)
    
    return predictor, prediction_results


if __name__ == "__main__":
    predictor, results = main()